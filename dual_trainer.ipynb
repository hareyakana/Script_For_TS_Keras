{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a training routine to shuffle and make sure every features is capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 5.0, 4.0\n",
    "\n",
    "from pyts.transformation import GADF,GASF\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import uproot\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "import fastcluster as fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = uproot.open(\"sig6.root\")[\"tree\"]\n",
    "Phonon = test.array(\"HeightHeat\")\n",
    "Photon = test.array(\"HeightLight\")\n",
    "eventid = test.array(\"EventNumber\")\n",
    "print(Photon[1].shape,Phonon.shape,eventid)\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "length = len(Photon)\n",
    "\n",
    "ped_heat = np.mean(Phonon[:,50:350], axis=1)\n",
    "ped_light = np.mean(Photon[:,50:350], axis=1)\n",
    "\n",
    "for i,j in enumerate(Phonon):\n",
    "        Phonon[i] = Phonon[i] - ped_heat[i]\n",
    "        Photon[i] = Photon[i] - ped_light[i]\n",
    "\n",
    "start_heat = np.argmax(Phonon[:,350:450], axis=1)\n",
    "# start_light = np.argmax(Photon[:,350:450], axis=1)\n",
    "start_heat +=350\n",
    "# start_light +=350\n",
    "\n",
    "# energy_heat = Phonon[:,800]\n",
    "# energy_heat2 = np.amax(Phonon[:,360:420], axis=1)\n",
    "energy_light = np.amax(Photon[:,360:420], axis=1)\n",
    "\n",
    "energy_heat = np.empty(length)\n",
    "energy_heat1 = np.empty(length)\n",
    "energy_heat2 = np.empty(length)\n",
    "\n",
    "for i in range(length):\n",
    "    energy_heat[i] = Phonon[i,int(start_heat[i]+400)]\n",
    "    energy_heat1[i] = Phonon[i,int(start_heat[i]+370)]\n",
    "    energy_heat2[i] = Phonon[i,int(start_heat[i]+350)]\n",
    "\n",
    "ratio = energy_light/energy_heat\n",
    "ratio1 = energy_light/energy_heat1\n",
    "ratio2 = energy_light/energy_heat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffler and flipper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data into suitable training format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizaion\n",
    "norm_heat = np.amax(Phonon,axis=1)\n",
    "norm_light = np.amax(Photon,axis=1)\n",
    "\n",
    "for i,j in enumerate(Phonon):\n",
    "    if norm_heat[i] > norm_light[i]:\n",
    "        Phonon[i] = Phonon[i]/norm_heat[i]\n",
    "        Photon[i] = Photon[i]/norm_heat[i]\n",
    "    if norm_light[i] > norm_heat[i]:\n",
    "        Phonon[i] = Phonon[i]/norm_light[i]\n",
    "        Photon[i] = Photon[i]/norm_light[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.zeros((len(Phonon),2,2000))\n",
    "for i in range(len(Phonon)):\n",
    "    dataset[i][0] = Phonon[i]\n",
    "    dataset[i][1] = Photon[i]\n",
    "\n",
    "del Phonon,Photon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 10000\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                         batch_size=BATCH,\n",
    "                         shuffle=False,\n",
    "                         num_workers=2)\n",
    "\n",
    "n_batches = int(len(dataset)/BATCH)\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 channel Auto-encoder network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Autoencoder_2c(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder_2c, self).__init__()        \n",
    "#         self.norm = nn.BatchNorm1d(1)\n",
    "        self.cv1 = nn.Conv1d(2, 32, kernel_size=8, stride=4, padding=0)\n",
    "        self.pl1 = nn.MaxPool1d(2, stride=4)\n",
    "        self.cv21 = nn.Conv1d(32, 32, kernel_size=8, stride=4, padding=0)\n",
    "        self.pl21 = nn.MaxPool1d(2, stride=4)\n",
    "        self.cv22 = nn.Conv1d(32, 32, kernel_size=8, stride=4, padding=0)\n",
    "        self.pl22 = nn.MaxPool1d(2, stride=4)\n",
    "                \n",
    "        self.ct1 = nn.ConvTranspose1d(32, 32, kernel_size=8, stride=4, padding=2)\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.ct2 = nn.ConvTranspose1d(32, 32, kernel_size=6, stride=4, padding=4)\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.ct3 = nn.ConvTranspose1d(32, 2, kernel_size=8, stride=4,padding=2)\n",
    "\n",
    "    def encoder(self, x):\n",
    "#         h0 = self.norm(x)\n",
    "        h1 = F.tanh(self.pl1(self.cv1(x)))\n",
    "        return self.pl21(self.cv21(h1)), self.pl22(self.cv22(h1))\n",
    "    \n",
    "    def reparameterise(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        h3 = F.leaky_relu(self.ct1(z))\n",
    "        h3 = self.up1(h3)\n",
    "        h3 = F.leaky_relu(self.ct2(h3))\n",
    "        h3 = self.up2(h3)\n",
    "        return F.leaky_relu(self.ct3(h3))\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        mu, logvar = self.encoder(inputs)\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar\n",
    "print(\"Autoencoder\")\n",
    "\n",
    "GEN = Autoencoder_2c()\n",
    "print(GEN)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(GEN.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "for parameter in GEN.parameters():\n",
    "    print(parameter.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the 2 channel auto-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "N_EPOCHS = 10\n",
    "# allow for manual keyboard interrupt\n",
    "try: \n",
    "    # loop through epochs\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        for batch_number, waveform in enumerate(train_loader):\n",
    "            \n",
    "            target = waveform.float()\n",
    "            outputs = GEN(waveform.float())\n",
    "\n",
    "            loss = criterion(outputs[0], target)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            if (batch_number +1)%5 == 0:\n",
    "                print(\"Epoch[%d/%d], Step[%d/%d], loss=%.6f\"\n",
    "                      %(epoch+1,\n",
    "                        N_EPOCHS,\n",
    "                        batch_number+1,\n",
    "                        n_batches,\n",
    "                        losTrues.data[0] ))\n",
    "except KeyboardInterrupt:\n",
    "    print('Training ended early.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(GEN.state_dict(),\"dual.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
