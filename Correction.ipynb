{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 336 ms, total: 1.45 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 5.0, 4.0\n",
    "\n",
    "from pyts.transformation import GADF,GASF\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import uproot\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 2)\n"
     ]
    }
   ],
   "source": [
    "# Specifically for Run009 good data custom set\n",
    "groups = np.array([[1,2],[1,2],[2,1],[1,2],\n",
    "                   [1,2],[2,1],[2,1],[1,2],\n",
    "                   [2,1],[2,1],[2,1],[2,1],\n",
    "                   [2,1],[1,2],[1,2],[2,1],\n",
    "                   [1,2],[2,1],[2,1],[1,2],\n",
    "                   [1,2],[2,1]])\n",
    "\n",
    "print(groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37 µs, sys: 1 µs, total: 38 µs\n",
      "Wall time: 42 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class Waveform():\n",
    "    \n",
    "    def __init__(self, path=None):\n",
    "        if path is None:\n",
    "            raise ValueError(\"Insert file path!\")\n",
    "#         if no_classes is None:\n",
    "#             raise ValueError(\"Number of classes?\")\n",
    "        \n",
    "        # Load PMTALL(sum of waveform of CANDLES), removing last portion of data\n",
    "        tree = uproot.open(path)[\"tree\"]\n",
    "        extra = np.arange(4096,4480)\n",
    "        pmtall = tree.array(\"PMTALL\")\n",
    "        pmtall = np.delete(pmtall, extra, axis=1)\n",
    "        pedestal = tree.array(\"Pedestal\")\n",
    "        pedestal_sum = pedestal[:,0]\n",
    "        for i in range(len(pedestal_sum)):\n",
    "            pmtall[i] = pedestal_sum[i] - pmtall[i]\n",
    "#         number = \n",
    "        \n",
    "        # random labelling(test purposes)\n",
    "        self.waveform = normalize(pmtall,axis=1,norm=\"l2\")\n",
    "#         self.label = np.random.randint(3,size=(len(pmtall),))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.waveform.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.waveform[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 3000\n",
    "dataset = Waveform(path=\"Run9goodDataQ_dualgate.root\")\n",
    "feat_loader = DataLoader(dataset=dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder\n",
      "Autoencoder(\n",
      "  (cv1): Conv1d(1, 32, kernel_size=(8,), stride=(4,), padding=(4,))\n",
      "  (pl1): MaxPool1d(kernel_size=2, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cv21): Conv1d(32, 16, kernel_size=(8,), stride=(4,), padding=(4,))\n",
      "  (pl21): MaxPool1d(kernel_size=2, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cv22): Conv1d(32, 16, kernel_size=(8,), stride=(4,), padding=(4,))\n",
      "  (pl22): MaxPool1d(kernel_size=2, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (ct1): ConvTranspose1d(16, 32, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      "  (up1): Upsample(scale_factor=2, mode=nearest)\n",
      "  (ct2): ConvTranspose1d(32, 32, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      "  (up2): Upsample(scale_factor=2, mode=nearest)\n",
      "  (ct3): ConvTranspose1d(32, 1, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      ")\n",
      "torch.Size([32, 1, 8])\n",
      "torch.Size([32])\n",
      "torch.Size([16, 32, 8])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 32, 8])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 32, 8])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 32, 8])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 1, 8])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,batch_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "#         self.norm = nn.BatchNorm1d(1)\n",
    "        self.cv1 = nn.Conv1d(1, 32, kernel_size=8, stride=4, padding=4)\n",
    "        self.pl1 = nn.MaxPool1d(2, stride=4)\n",
    "        self.cv21 = nn.Conv1d(32, 16, kernel_size=8, stride=4, padding=4)\n",
    "        self.pl21 = nn.MaxPool1d(2, stride=4)\n",
    "        self.cv22 = nn.Conv1d(32, 16, kernel_size=8, stride=4, padding=4)\n",
    "        self.pl22 = nn.MaxPool1d(2, stride=4)\n",
    "                \n",
    "        self.ct1 = nn.ConvTranspose1d(16, 32, kernel_size=8, stride=4, padding=2)\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.ct2 = nn.ConvTranspose1d(32, 32, kernel_size=8, stride=4, padding=2)\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.ct3 = nn.ConvTranspose1d(32, 1, kernel_size=8, stride=4,padding=2)\n",
    "\n",
    "    def encoder(self, x):\n",
    "#         h0 = self.norm(x)\n",
    "        h1 = F.tanh(self.pl1(self.cv1(x)))\n",
    "        return self.pl21(self.cv21(h1)), self.pl22(self.cv22(h1))\n",
    "    \n",
    "    def reparameterise(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        h3 = F.leaky_relu(self.ct1(z))\n",
    "        h3 = self.up1(h3)\n",
    "        h3 = F.leaky_relu(self.ct2(h3))\n",
    "        h3 = self.up2(h3)\n",
    "        return F.leaky_relu(self.ct3(h3))\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        mu, logvar = self.encoder(inputs)\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar\n",
    "print(\"Autoencoder\")\n",
    "\n",
    "GEN = Autoencoder(BATCH_SIZE)\n",
    "print(GEN)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(GEN.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "for parameter in GEN.parameters():\n",
    "    print(parameter.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load(\"GEN_WEIGHT.pkl\")\n",
    "GEN.load_state_dict(torch.load(\"GEN_WEIGHT_quarter.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(x):\n",
    "    # first move to GPU, if necessary\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        \n",
    "    return Variable(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rearrage cluster arragement and create the correctly labelled CNN clustered features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 256)\n",
      "0 [1 2 3 4]\n",
      "[4 2 4 ... 1 4 4]\n",
      "[4 2 4 ... 1 4 4]\n",
      "(3000, 256)\n",
      "1 [1 2 3 4]\n",
      "[4 4 4 ... 4 4 4]\n",
      "[4 4 4 ... 4 4 4]\n",
      "(3000, 256)\n",
      "2 [1 2 3 4]\n",
      "[4 3 1 ... 2 2 2]\n",
      "[2 1 3 ... 4 4 4]\n",
      "(3000, 256)\n",
      "3 [1 2 3 4]\n",
      "[4 4 4 ... 4 4 1]\n",
      "[4 4 4 ... 4 4 1]\n",
      "(3000, 256)\n",
      "4 [1 2 3 4]\n",
      "[3 4 4 ... 1 4 4]\n",
      "[3 4 4 ... 1 4 4]\n",
      "(3000, 256)\n",
      "5 [1 2 3 4]\n",
      "[2 3 4 ... 2 2 2]\n",
      "[4 1 2 ... 4 4 4]\n",
      "(3000, 256)\n",
      "6 [1 2 3 4]\n",
      "[3 2 3 ... 3 3 2]\n",
      "[1 4 1 ... 1 1 4]\n",
      "(3000, 256)\n",
      "7 [1 2 3 4]\n",
      "[1 3 4 ... 4 4 4]\n",
      "[1 3 4 ... 4 4 4]\n",
      "(3000, 256)\n",
      "8 [1 2 3 4]\n",
      "[2 3 2 ... 2 2 2]\n",
      "[4 1 4 ... 4 4 4]\n",
      "(3000, 256)\n",
      "9 [1 2 3 4]\n",
      "[3 4 2 ... 1 3 2]\n",
      "[1 2 4 ... 3 1 4]\n",
      "(3000, 256)\n",
      "10 [1 2 3 4]\n",
      "[2 2 2 ... 2 2 2]\n",
      "[4 4 4 ... 4 4 4]\n",
      "(3000, 256)\n",
      "11 [1 2 3 4]\n",
      "[2 4 2 ... 2 1 2]\n",
      "[4 2 4 ... 4 3 4]\n",
      "(3000, 256)\n",
      "12 [1 2 3 4]\n",
      "[2 2 2 ... 2 2 2]\n",
      "[4 4 4 ... 4 4 4]\n",
      "(3000, 256)\n",
      "13 [1 2 3 4]\n",
      "[4 4 4 ... 4 4 1]\n",
      "[4 4 4 ... 4 4 1]\n",
      "(3000, 256)\n",
      "14 [1 2 3 4]\n",
      "[4 4 4 ... 1 4 4]\n",
      "[4 4 4 ... 1 4 4]\n",
      "(3000, 256)\n",
      "15 [1 2 3 4]\n",
      "[2 2 4 ... 2 2 2]\n",
      "[4 4 2 ... 4 4 4]\n",
      "(3000, 256)\n",
      "16 [1 2 3 4]\n",
      "[3 4 4 ... 4 4 1]\n",
      "[3 4 4 ... 4 4 1]\n",
      "(3000, 256)\n",
      "17 [1 2 3 4]\n",
      "[2 2 3 ... 2 2 3]\n",
      "[4 4 1 ... 4 4 1]\n",
      "(3000, 256)\n",
      "18 [1 2 3 4]\n",
      "[2 4 1 ... 2 1 4]\n",
      "[4 2 3 ... 4 3 2]\n",
      "(3000, 256)\n",
      "19 [1 2 3 4]\n",
      "[1 1 4 ... 3 4 4]\n",
      "[1 1 4 ... 3 4 4]\n",
      "(3000, 256)\n",
      "20 [1 2 3 4]\n",
      "[4 4 4 ... 4 4 4]\n",
      "[4 4 4 ... 4 4 4]\n",
      "(2675, 256)\n",
      "21 [1 2 3 4]\n",
      "[4 2 2 ... 4 1 1]\n",
      "[2 4 4 ... 2 3 3]\n",
      "CPU times: user 1min 4s, sys: 18 s, total: 1min 22s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "label = []\n",
    "try:\n",
    "    for batch_number, waveform in enumerate(feat_loader):\n",
    "        \n",
    "        batch_size = waveform.size()[0]\n",
    "        waveform_in = to_var(waveform.view(batch_size,1,4096)) \n",
    "        feat = GEN.encoder(waveform_in)\n",
    "        \n",
    "        features = np.reshape(feat[0].detach().numpy(),(len(waveform),-1))\n",
    "        print(features.shape)\n",
    "        Linkage = linkage(features, method=\"ward\")\n",
    "#         clusters = fcluster(Linkage, 1.5, criterion='distance')\n",
    "#         print(batch_number,np.unique(clusters))\n",
    "        \n",
    "#         if groups[batch_number,0]==2:\n",
    "#             clusters = -(clusters - 3)\n",
    "#         label.append(clusters)\n",
    "        \n",
    "        clusters = fcluster(Linkage, 1.0, criterion='distance')\n",
    "        print(batch_number,np.unique(clusters))\n",
    "        \n",
    "        print(clusters)\n",
    "        if groups[batch_number,0]==2:\n",
    "            for i,j in enumerate(clusters):\n",
    "                if j==1 or j==2:\n",
    "                    clusters[i] = clusters[i] + 2\n",
    "                if j==3 or j==4:\n",
    "                    clusters[i] = clusters[i] - 2\n",
    "        print(clusters)\n",
    "        \n",
    "        label.append(clusters)\n",
    "\n",
    "#         fig = plt.figure(figsize=(6, 4))\n",
    "#         dn = dendrogram(Linkage)\n",
    "#         plt.title(batch_number)\n",
    "#         plt.show()\n",
    "                 \n",
    "except KeyboardInterrupt:\n",
    "    print('Training ended early.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_label = np.empty(65675)\n",
    "for i in range(22):\n",
    "    if i==21:\n",
    "        correct_label[i*3000:] = label[i]\n",
    "    else:\n",
    "        correct_label[i*3000:(i+1)*3000] = label[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"label\",correct_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65675,)\n"
     ]
    }
   ],
   "source": [
    "print(correct_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
