{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.10/02\n",
      "CPU times: user 1.5 s, sys: 592 ms, total: 2.09 s\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from root_pandas import read_root\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 12.0, 8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABC - Approximate Bayesian Computation, Inference statistical method.???\n",
    "\n",
    "# Bayesian Deep learning, Conquering Uncertainty\n",
    "\n",
    "### Write a data generator, read from .root, 1D strings then transform it into 2D images\n",
    "\n",
    "better memory handling for 256x256 images. storing it on RAM can take up way too much!!\n",
    "\n",
    "### Not very well verse in writing this type of operations in python. ned to figure out to better handle it.\n",
    "\n",
    "standard method takes about 2 GB, images x16, 32GB!!!, that too much for any normal operating system's memory can handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 1)\n",
      "(1, 64, 64, 1)\n",
      "(1, 64, 64, 1)\n",
      "CPU times: user 27.8 s, sys: 3.11 s, total: 31 s\n",
      "Wall time: 32.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyts.transformation import GADF,GASF\n",
    "from sklearn.preprocessing import normalize\n",
    "from root_numpy import tree2array,array2tree,array2root\n",
    "import ROOT\n",
    "import keras\n",
    "\n",
    "def reader_pmt(path):\n",
    "    extra = np.arange(4096, 4480)\n",
    "    x_file = ROOT.TFile(path)\n",
    "    x_tree = x_file.Get(\"tree\")\n",
    "    x_pmtall = tree2array(x_tree, branches=\"PMTALL\")\n",
    "    x = np.delete(x_pmtall, extra, axis=1)\n",
    "    return x\n",
    "\n",
    "def label(q,k):\n",
    "    x = np.zeros(len(q))\n",
    "    for i in range(len(q)):\n",
    "        x[i] = k\n",
    "    return x\n",
    "\n",
    "def sep(q,k,z):\n",
    "    y = label(q,k)\n",
    "    x1, x2 ,x3 = np.split(q,[int(len(q)*0.6),int(len(q)*0.8)])\n",
    "    y1, y2 ,y3 = np.split(y,[int(len(q)*0.6),int(len(q)*0.8)])\n",
    "    if z == 0:\n",
    "        return x1, y1\n",
    "    if z == 1:\n",
    "        return x2, y2\n",
    "    if z == 2:\n",
    "        return x3, y3\n",
    "    \n",
    "def comb(one,two,three,four,five,portion):\n",
    "    one1,one2 = sep(one,0,portion)\n",
    "    two1,two2 = sep(two,1,portion)\n",
    "    three1,three2 = sep(three,2,portion)\n",
    "    four1,four2 = sep(four,3,portion)\n",
    "    five1,five2 = sep(five,4,portion)\n",
    "    six1,six2 = sep(six,5,portion)\n",
    "    seven1,seven2 = sep(seven,6,portion)\n",
    "    \n",
    "    z = np.concatenate((one1,two1,three1,four1,five1,six1,seven1),axis=0)\n",
    "    y = np.concatenate((one2,two2,three2,four2,five2,six2,seven2),axis=0)\n",
    "    return z, y\n",
    "\n",
    "import random\n",
    "classes = 5\n",
    "def generator(x):\n",
    "    while 1:\n",
    "        alpha = reader_pmt(\"Alpha_2280_2350.root\")\n",
    "        bad1 = reader_pmt(\"BAD_DATA_QUALITY_1.root\")\n",
    "        bad2 = reader_pmt(\"BAD_DATA_QUALITY_2.root\")\n",
    "        piled = reader_pmt(\"Piled_2.root\")\n",
    "        ls = reader_pmt(\"LS.root\")\n",
    "        lsbeta = reader_pmt(\"LS_BETA.root\")\n",
    "        ref = reader_pmt(\"RefPulse009.root\")\n",
    "        \n",
    "        z1, z2 = comb(piled,ref,alpha,bad1,bad2,x)\n",
    "        s = np.random.permutation(np.arange(len(z2)))\n",
    "        z1 = z1[s]\n",
    "        z2 = z2[s]\n",
    "#         print(len(z2))\n",
    "\n",
    "        gasf = GASF(image_size=64, overlapping=False, scale='-1')\n",
    "        for i in range(len(z2)):\n",
    "            p = np.expand_dims(z1[i],axis=0)\n",
    "            p = gasf.transform(p)\n",
    "            q = keras.utils.to_categorical(z2[i],classes)\n",
    "            yield(p,q)\n",
    "        \n",
    "# print(len(x_nor))\n",
    "test = generator(0)\n",
    "# print(len(test))\n",
    "print(next(test)[0].shape)\n",
    "# print(next(test)[1].shape)\n",
    "# print(next(test))\n",
    "# print(next(test))\n",
    "test = generator(1)\n",
    "# print(len(test))\n",
    "print(next(test)[0].shape)\n",
    "# print(next(test)[1].shape)\n",
    "test = generator(2)\n",
    "# print(len(test))\n",
    "print(next(test)[0].shape)\n",
    "# print(next(test)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 8)         16        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        144       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 568,645\n",
      "Trainable params: 568,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization, Embedding, LSTM\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=1, activation=\"relu\", input_shape=(64,64,1)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(16, 1, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(32, 1, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "# model.add(Dense(16,activation=\"relu\"))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(8,activation=\"relu\"))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(classes,activation=\"softmax\"))\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_gen = generator(0)\n",
    "val_gen = generator(1)\n",
    "test_gen = generator(2)\n",
    "steps_t = 17175\n",
    "steps_vt  = 5727\n",
    "\n",
    "history = model.fit_generator(train_gen,steps_per_epoch=steps_t, epochs=10, verbose=1, validation_data=val_gen,validation_steps=steps_vt)\n",
    "model.save(\"CNN_256_256_5_classes_noLS_LSBETA.h5\")\n",
    "score = model.evaluate_generator(test_gen,steps=8059)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "print(history.history.keys())\n",
    "plt.figure()\n",
    "plt.title(\"Classification accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(history.history['acc'],label=\"training accuracy\")\n",
    "plt.plot(history.history['val_acc'],label=\"Validation accuracy\")\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Loss function\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(history.history['loss'],label=\"training loss\")\n",
    "plt.plot(history.history['val_loss'],label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification accuracy =\",history.history['val_acc'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old codes, do not run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 26s, sys: 46.2 s, total: 9min 12s\n",
      "Wall time: 8min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "piled = reader_pmt(\"Piled_2.root\")\n",
    "ls = reader_pmt(\"LS.root\")\n",
    "lsbeta = reader_pmt(\"LS_BETA.root\")\n",
    "ref = reader_pmt(\"RefPulse009.root\")\n",
    "\n",
    "gadf = GADF(image_size=256, overlapping=False, scale='-1')\n",
    "piled_gadf = gadf.transform(piled)\n",
    "ls_gadf = gadf.transform(ls)\n",
    "lsbeta_gadf = gadf.transform(lsbeta)\n",
    "ref_gadf = gadf.transform(ref)\n",
    "\n",
    "del piled,ls,lsbeta,ref"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
