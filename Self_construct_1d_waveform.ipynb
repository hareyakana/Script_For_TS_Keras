{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 s, sys: 471 ms, total: 2.47 s\n",
      "Wall time: 3.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 12.0, 8.0\n",
    "\n",
    "from pyts.transformation import GADF,GASF\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import uproot\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Concatenate, Dense, Activation, Reshape, Conv1D , Conv2D, MaxPooling1D, MaxPooling2D\n",
    "from keras.layers import Dropout, Flatten, BatchNormalization, Embedding, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-construct waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard(x,height,decay):\n",
    "    y = height*np.exp(-x*decay)\n",
    "    return y\n",
    "\n",
    "def shifter(x,starts):\n",
    "    L = int(starts*len(x))\n",
    "    y = np.zeros(len(x))\n",
    "    y[:L] = np.zeros(L) \n",
    "    y[L:] = x[:(len(x)-L)]\n",
    "    return y\n",
    "\n",
    "def comb_standard(x,second,height_1,decay_1,height_2,decay_2):\n",
    "    L = int(second*len(x))\n",
    "    y = np.zeros(len(x))\n",
    "    y[:L] = standard(x[:L],height_1,decay_1)\n",
    "    y[L:] = standard(x[:(len(x)-L)],height_2,decay_2)\n",
    "    return y\n",
    "\n",
    "def noiser(x,strength):\n",
    "    y = x + np.random.normal(0,strength,len(x))\n",
    "    return y\n",
    "\n",
    "def noiser_long(x,strength):\n",
    "    noise = np.random.normal(0,strength,len(x))\n",
    "    y = x + np.cumsum(noise)*strength\n",
    "    return y\n",
    "\n",
    "def noiser_comb(x,sepfact,strength):\n",
    "    L = int(sepfact*len(x))\n",
    "    x[:L] = noiser(x[:L],strength)\n",
    "    x[L:] = noiser_long(x[L:],strength)\n",
    "    return x\n",
    "\n",
    "def array_maker(entries):\n",
    "    x = np.arange(0,1,1/4096)\n",
    "    x = np.expand_dims(x,axis=0)\n",
    "    x = np.tile(x,[entries,1])\n",
    "    return x\n",
    "\n",
    "def double(x,second,height_1,decay_1,height_2,decay_2,starts,sepfact=0.15,strength=0.02):\n",
    "    y = comb_standard(x,second,height_1,decay_1,height_2,decay_2)\n",
    "    y = shifter(y,starts)\n",
    "    y = noiser_comb(y,sepfact,strength)\n",
    "    return y\n",
    "\n",
    "def single(x,height,decay,starts,sepfact=0.15,strength=0.02):\n",
    "    y = standard(x,height,decay)\n",
    "    y = shifter(y,starts)\n",
    "    y = noiser_comb(y,sepfact,strength)\n",
    "    return y\n",
    "\n",
    "def event_creators_single(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(1,0.01)\n",
    "        r = np.random.normal(5,2)\n",
    "        s = np.random.normal(0.03,0.005)\n",
    "        x[i] = single(x[i],w,r,s)\n",
    "    return x\n",
    "\n",
    "def event_creators_single_2(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(1,0.01)\n",
    "        r = np.random.normal(10,2)\n",
    "        s = np.random.normal(0.03,0.005)\n",
    "        x[i] = single(x[i],w,r,s)\n",
    "    return x\n",
    "\n",
    "def event_creators_single_3(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(1,0.1)\n",
    "        r = np.random.normal(4,1)\n",
    "        s = np.random.normal(0.03,0.005)\n",
    "        x[i] = single(x[i],w,r,s)\n",
    "    return x\n",
    "\n",
    "def event_creators_sharp(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(1,0.01)\n",
    "        r = np.random.normal(100,20)\n",
    "        s = np.random.normal(0.03,0.005)\n",
    "        x[i] = single(x[i],w,r,s)    \n",
    "    return x\n",
    "\n",
    "def event_creators_double_equal(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(0.2,0.01)\n",
    "        p = np.random.normal(1,0.01)\n",
    "        q = np.random.normal(5,2)\n",
    "        r = np.random.normal(1,0.01)\n",
    "        s = np.random.normal(5,2)\n",
    "        t = np.random.normal(0.03,0.005)\n",
    "        x[i] = double(x[i],w,p,q,r,s,t)\n",
    "    return x\n",
    "    \n",
    "def event_creators_double_unequal(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(0.2,0.01)\n",
    "        p = np.random.normal(1,0.2)\n",
    "        q = np.random.normal(50,10)\n",
    "        r = np.random.normal(1,0.2)\n",
    "        s = np.random.normal(50,10)\n",
    "        t = np.random.normal(0.03,0.005)\n",
    "        x[i] = double(x[i],w,p,q,r,s,t)\n",
    "    return x\n",
    "\n",
    "def event_creators_sharp_fat(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(0.015,0.001)\n",
    "        p = np.random.normal(1,0.2)\n",
    "        q = np.random.normal(100,20)\n",
    "        r = np.random.normal(0.2,0.05)\n",
    "        s = np.random.normal(5,2)\n",
    "        t = np.random.normal(0.03,0.005)\n",
    "        x[i] = double(x[i],w,p,q,r,s,t)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 7\n",
    "group = 5\n",
    "training_ratio = 0.7\n",
    "validation_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "\n",
    "def label(q,k):\n",
    "    x = np.zeros(len(q))\n",
    "    for i in range(len(q)):\n",
    "        x[i] = k\n",
    "    return x\n",
    "\n",
    "def sep(q,k,z):\n",
    "    y = label(q,k)\n",
    "    x1, x2 ,x3 = np.split(q,[int(len(q)*training_ratio),int(len(q)*(training_ratio+validation_ratio))])\n",
    "    y1, y2 ,y3 = np.split(y,[int(len(q)*training_ratio),int(len(q)*(training_ratio+validation_ratio))])\n",
    "    if z == 0:\n",
    "        return x1, y1\n",
    "    if z == 1:\n",
    "        return x2, y2\n",
    "    if z == 2:\n",
    "        return x3, y3\n",
    "    \n",
    "def comb(one,two,three,four,five,portion):\n",
    "    one1,one2 = sep(one,0,portion)\n",
    "    two1,two2 = sep(two,1,portion)\n",
    "    three1,three2 = sep(three,2,portion)\n",
    "    four1,four2 = sep(four,3,portion)\n",
    "    five1,five2 = sep(five,4,portion)\n",
    "#     six1,six2 = sep(six,5,portion)\n",
    "#     seven1,seven2 = sep(seven,6,portion)\n",
    "    \n",
    "    z = np.concatenate((one1,two1,three1,four1,five1),axis=0)\n",
    "    y = np.concatenate((one2,two2,three2,four2,five2),axis=0)\n",
    "    return z, y\n",
    "\n",
    "# def generator(x):\n",
    "#     while 1:\n",
    "#         beta = event_creators_single(1000)\n",
    "#         ls = event_creators_sharp(1000)\n",
    "#         dp_e = event_creators_double_equal(1000)\n",
    "#         dp_ue = event_creators_double_unequal(1000)\n",
    "#         lsbeta = event_creators_sharp_fat(1000)\n",
    "        \n",
    "#         alpha = event_creators_single_2(1000)\n",
    "#         gamma = event_creators_single_3(1000)\n",
    "        \n",
    "#         z1, z2 = comb(beta,ls,dp_e,dp_ue,lsbeta,alpha,gamma,x)\n",
    "#         s = np.random.permutation(np.arange(len(z2)))\n",
    "#         z1 = z1[s]\n",
    "#         z2 = z2[s]\n",
    "# #         print(len(z1))\n",
    "#         gasf = GASF(image_size=128, overlapping=False, scale='-1')\n",
    "        \n",
    "#         for i in range(len(z2)):\n",
    "#             d1 = np.expand_dims(z1[i],axis=0)\n",
    "# #             p = gasf.transform(d1)\n",
    "#             q = keras.utils.to_categorical(z2[i],classes)\n",
    "#             r = normalize(d1,norm=\"l1\")\n",
    "#             yield r,q\n",
    "\n",
    "# test = generator(2)\n",
    "# # print(next(test)[0][0])\n",
    "# print(next(test)[0][0].shape)\n",
    "# # print(next(test)[0][1].shape)\n",
    "# print(next(test)[1].shape)\n",
    "\n",
    "# from pyts.visualization import plot_gasf\n",
    "# plot_gasf(next(test)[0], image_size=128, overlapping=False, scale='-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "(1, 7)\n"
     ]
    }
   ],
   "source": [
    "def reader_pmtall(path):\n",
    "    extra = np.arange(4096, 4480)\n",
    "    \n",
    "    tree = uproot.open(path)[\"tree\"]\n",
    "    pmtall = tree.array(\"PMTALL\")\n",
    "    pmtall = np.delete(pmtall, extra, axis=1)\n",
    "    return pmtall\n",
    "\n",
    "def reader(path,branch,number):\n",
    "    tree = uproot.open(path)[\"tree\"]\n",
    "    column = tree.array(branch)\n",
    "    column = column[:,number]\n",
    "    return column\n",
    "\n",
    "def reader_lone(path,branch):\n",
    "    tree = uproot.open(path)[\"tree\"]\n",
    "    column = tree.array(branch)\n",
    "    return column\n",
    "\n",
    "def pmtall_pedestal(path):\n",
    "    pedestal = reader(path,\"Pedestal\",0)\n",
    "    pmtall = reader_pmtall(path)\n",
    "    for i in range(len(pedestal)):\n",
    "        pmtall[i] = -(pmtall[i]-pedestal[i])\n",
    "    \n",
    "    return pmtall\n",
    "\n",
    "def generator(x):\n",
    "    while 1:\n",
    "        alpha = pmtall_pedestal(\"Alpha.root\")\n",
    "#         bad1 = pmtall_pedestal(\"BAD_DATA_QUALITY_1.root\")\n",
    "#         bad2 = pmtall_pedestal(\"BAD_DATA_QUALITY_2.root\")\n",
    "        piled = pmtall_pedestal(\"Piled_2.root\")\n",
    "        ls = pmtall_pedestal(\"LS.root\")\n",
    "        lsbeta = pmtall_pedestal(\"lsbeta.root\")\n",
    "        ref = pmtall_pedestal(\"RefPulse009.root\")\n",
    "        \n",
    "        z1, z2 = comb(piled,ref,alpha,ls,lsbeta,x)\n",
    "        s = np.random.permutation(np.arange(len(z2)))\n",
    "        z1 = z1[s]\n",
    "        z2 = z2[s]\n",
    "\n",
    "#         para_piled = parameters(\"Piled_2.root\")\n",
    "#         para_ref = parameters(\"RefPulse009.root\")\n",
    "#         para_alpha = parameters(\"Alpha.root\")\n",
    "#         para_ls = parameters(\"LS.root\")\n",
    "#         para_lsbeta = parameters(\"lsbeta.root\")\n",
    "        \n",
    "#         z3, z4 = comb5(para_piled,para_ref,para_alpha,para_ls,para_lsbeta,x)        \n",
    "#         z3 = z3[s] \n",
    "#         z4 = z4[s]\n",
    "\n",
    "        gasf = GASF(image_size=128, overlapping=False, scale='-1')\n",
    "        \n",
    "        for i in range(len(z2)):\n",
    "            d1 = np.expand_dims(z1[i],axis=0)\n",
    "            q = keras.utils.to_categorical(z2[i],classes)\n",
    "            r = normalize(d1,norm=\"l1\")\n",
    "            s = np.expand_dims(q,axis=0)\n",
    "            yield r,s\n",
    "\n",
    "test = generator(0)\n",
    "# print(next(test)[0][0])\n",
    "print(next(test)[0].shape)\n",
    "# print(next(test)[0][1].shape)\n",
    "print(next(test)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4096, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 4096, 32)          2080      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1024, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1024, 16)          32784     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 512, 16)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                524352    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 563,831\n",
      "Trainable params: 563,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model2 = Reshape((4096,1),input_shape=(4096,))(feeder_1d)\n",
    "#     model2 = Conv1D(32, kernel_size=64, strides=1,padding='same',activation=\"relu\")(model2)\n",
    "#     model2 = MaxPooling1D(pool_size=4,padding='same')(model2)\n",
    "#     model2 = Conv1D(16, kernel_size=64, strides=1,padding='same',activation=\"relu\")(model2)\n",
    "#     model2 = MaxPooling1D(pool_size=2,padding='same')(model2)\n",
    "\n",
    "def multiple_inputs():\n",
    "    feeder_1d = Input(shape=(4096,))\n",
    "    model1 = Reshape((4096,1),input_shape=(4096,))(feeder_1d)\n",
    "    model1 = Conv1D(32, kernel_size=64, strides=1,padding='same',activation=\"relu\")(model1)\n",
    "    model1 = MaxPooling1D(pool_size=4,padding='same')(model1)\n",
    "    model1 = Conv1D(16, kernel_size=64, strides=1,padding='same',activation=\"relu\")(model1)\n",
    "    model1 = MaxPooling1D(pool_size=2,padding='same')(model1)\n",
    "    model1 = Flatten()(model1)\n",
    "    model1 = Dense(64,activation=\"relu\")(model1)\n",
    "    model1 = Dropout(0.2)(model1)\n",
    "    model1 = Dense(64,activation=\"relu\")(model1)\n",
    "    model1 = Dropout(0.2)(model1)\n",
    "    waveform_1d_out = Dense(7,activation=\"sigmoid\")(model1)\n",
    "    \n",
    "#     feeder_2d = Input(shape=(128,128))\n",
    "#     model2 = Reshape((128,128,1),input_shape=(128,128))(feeder_2d)\n",
    "#     model2 = Conv2D(64, kernel_size=(8,8),strides=4,padding='same')(model2)\n",
    "#     model2 = MaxPooling2D(pool_size=2)(model2)\n",
    "#     model2 = Activation(\"relu\")(model2)\n",
    "#     model2 = Conv2D(32, kernel_size=(4,4),strides=4,padding='same')(model2)\n",
    "#     model2 = MaxPooling2D(pool_size=2)(model2)\n",
    "#     model2 = Activation(\"relu\")(model2)\n",
    "#     model2 = Dropout(0.2)(model2)\n",
    "#     model2 = Flatten()(model2)\n",
    "# #     model2 = Dense(256,activation=\"relu\")(model2)\n",
    "# #     model2 = Dropout(0.3)(model2)\n",
    "#     model2 = Dense(64,activation=\"relu\")(model2)\n",
    "#     model2 = Dropout(0.3)(model2)\n",
    "#     model2 = Dense(64,activation=\"relu\")(model2)\n",
    "#     model2 = Dropout(0.3)(model2)\n",
    "#     waveform_2d_out = Dense(7,activation=\"sigmoid\")(model2)\n",
    "    \n",
    "#     feeder_para = Input(shape=(10,))\n",
    "#     model3 = Dense(64,activation=\"relu\")(feeder_para)\n",
    "#     model3 = Dropout(0.2)(model3)\n",
    "#     model3 = Dense(64,activation=\"relu\")(model3)\n",
    "#     model3 = Dropout(0.2)(model3)\n",
    "# #     model3 = Dense(128,activation=\"relu\")(model3)\n",
    "# #     model3 = Dropout(0.2)(model3)\n",
    "#     para_dense = Dense(7,activation=\"sigmoid\")(model3)\n",
    "    \n",
    "#     x = keras.layers.concatenate([waveform_1d_out, waveform_2d_out])\n",
    "#     x = Dense(256,activation=\"relu\")(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = Dense(256,activation=\"relu\")(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     main_output = Dense(7, activation='softmax', name='main_output')(x)\n",
    "    \n",
    "    model = Model(inputs=[feeder_1d],outputs=[waveform_1d_out])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "mult = multiple_inputs()\n",
    "mult.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "21430/21430 [==============================] - 428s 20ms/step - loss: 0.0882 - acc: 0.9616 - val_loss: 0.0347 - val_acc: 0.9877\n",
      "Epoch 2/5\n",
      "18310/21430 [========================>.....] - ETA: 51s - loss: 0.0360 - acc: 0.9887"
     ]
    }
   ],
   "source": [
    "train_gen = generator(0)\n",
    "val_gen = generator(1)\n",
    "test_gen = generator(2)\n",
    "\n",
    "steps_t = 21430\n",
    "steps_vt = 3062\n",
    "\n",
    "history = mult.fit_generator(train_gen,steps_per_epoch=steps_t, epochs=5, verbose=1, validation_data=val_gen,validation_steps=steps_vt)\n",
    "print(history.history.keys())\n",
    "plt.figure()\n",
    "plt.title(\"Classification accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(history.history['acc'],label=\"training accuracy\")\n",
    "plt.plot(history.history['val_acc'],label=\"Validation accuracy\")\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Loss function\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(history.history['loss'],label=\"training loss\")\n",
    "plt.plot(history.history['val_loss'],label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification accuracy =\",history.history['val_acc'][-1])\n",
    "\n",
    "mult.save(\"cnn-based-autoencoder.h5\")\n",
    "\n",
    "score = mult.evaluate_generator(test_gen,steps=1531)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult.save(\"tuned_data_1d.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
