{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Using Convolution Filters with clustering techniques (DBSCAN) and Understanding of CNN via layer wise relevance propagation (or similar techniques) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 3.1 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 5.0, 4.0\n",
    "\n",
    "from pyts.transformation import GADF,GASF\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import uproot\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard(x,height,decay):\n",
    "    y = height*np.exp(-x*decay)\n",
    "    return y\n",
    "\n",
    "def shifter(x,starts):\n",
    "    L = int(starts*len(x))\n",
    "    y = np.zeros(len(x))\n",
    "    y[:L] = np.zeros(L) \n",
    "    y[L:] = x[:(len(x)-L)]\n",
    "    return y\n",
    "\n",
    "def comb_standard(x,second,height_1,decay_1,height_2,decay_2):\n",
    "    L = int(second*len(x))\n",
    "    y = np.zeros(len(x))\n",
    "    y[:L] = standard(x[:L],height_1,decay_1)\n",
    "    y[L:] = standard(x[:(len(x)-L)],height_2,decay_2)\n",
    "    return y\n",
    "\n",
    "def noiser(x,strength):\n",
    "    y = x + np.random.normal(0,strength,len(x))\n",
    "    return y\n",
    "\n",
    "def noiser_long(x,strength):\n",
    "    noise = np.random.normal(0,strength,len(x))\n",
    "    y = x + np.cumsum(noise)*strength\n",
    "    return y\n",
    "\n",
    "def noiser_comb(x,sepfact,strength):\n",
    "    L = int(sepfact*len(x))\n",
    "    x[:L] = noiser(x[:L],strength)\n",
    "    x[L:] = noiser_long(x[L:],strength)\n",
    "    return x\n",
    "\n",
    "def array_maker(entries):\n",
    "    x = np.arange(0,1,1/4096)\n",
    "    x = np.expand_dims(x,axis=0)\n",
    "    x = np.tile(x,[entries,1])\n",
    "    return x\n",
    "\n",
    "def double(x,second,height_1,decay_1,height_2,decay_2,starts,sepfact=0.15,strength=0.02):\n",
    "    y = comb_standard(x,second,height_1,decay_1,height_2,decay_2)\n",
    "    y = shifter(y,starts)\n",
    "    y = noiser_comb(y,sepfact,strength)\n",
    "    return y\n",
    "\n",
    "def single(x,height,decay,starts,sepfact=0.15,strength=0.02):\n",
    "    y = standard(x,height,decay)\n",
    "    y = shifter(y,starts)\n",
    "    y = noiser_comb(y,sepfact,strength)\n",
    "    return y\n",
    "\n",
    "def event_creators_single(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(1,0.01)\n",
    "        r = np.random.normal(5,2)\n",
    "        s = np.random.normal(0.03,0.005)\n",
    "        x[i] = single(x[i],w,r,s)\n",
    "    return x\n",
    "\n",
    "def event_creators_single_2(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(1,0.01)\n",
    "        r = np.random.normal(10,2)\n",
    "        s = np.random.normal(0.03,0.005)\n",
    "        x[i] = single(x[i],w,r,s)\n",
    "    return x\n",
    "\n",
    "def event_creators_single_3(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(1,0.1)\n",
    "        r = np.random.normal(4,1)\n",
    "        s = np.random.normal(0.03,0.005)\n",
    "        x[i] = single(x[i],w,r,s)\n",
    "    return x\n",
    "\n",
    "def event_creators_sharp(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(1,0.01)\n",
    "        r = np.random.normal(100,20)\n",
    "        s = np.random.normal(0.03,0.005)\n",
    "        x[i] = single(x[i],w,r,s)    \n",
    "    return x\n",
    "\n",
    "def event_creators_double_equal(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(0.2,0.01)\n",
    "        p = np.random.normal(1,0.01)\n",
    "        q = np.random.normal(5,2)\n",
    "        r = np.random.normal(1,0.01)\n",
    "        s = np.random.normal(5,2)\n",
    "        t = np.random.normal(0.03,0.005)\n",
    "        x[i] = double(x[i],w,p,q,r,s,t)\n",
    "    return x\n",
    "    \n",
    "def event_creators_double_unequal(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(0.2,0.01)\n",
    "        p = np.random.normal(1,0.2)\n",
    "        q = np.random.normal(50,10)\n",
    "        r = np.random.normal(1,0.2)\n",
    "        s = np.random.normal(50,10)\n",
    "        t = np.random.normal(0.03,0.005)\n",
    "        x[i] = double(x[i],w,p,q,r,s,t)\n",
    "    return x\n",
    "\n",
    "def event_creators_sharp_fat(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(0.015,0.001)\n",
    "        p = np.random.normal(1,0.2)\n",
    "        q = np.random.normal(100,20)\n",
    "        r = np.random.normal(0.2,0.05)\n",
    "        s = np.random.normal(5,2)\n",
    "        t = np.random.normal(0.03,0.005)\n",
    "        x[i] = double(x[i],w,p,q,r,s,t)\n",
    "    return x\n",
    "\n",
    "def label(q,k):\n",
    "    x = np.zeros(len(q))\n",
    "    for i in range(len(q)):\n",
    "        x[i] = k\n",
    "    return x\n",
    "\n",
    "def sep(q,k,z):\n",
    "    y = label(q,k)\n",
    "    x1, x2 ,x3 = np.split(q,[int(len(q)*training_ratio),int(len(q)*(training_ratio+validation_ratio))])\n",
    "    y1, y2 ,y3 = np.split(y,[int(len(q)*training_ratio),int(len(q)*(training_ratio+validation_ratio))])\n",
    "    if z == 0:\n",
    "        return x1, y1\n",
    "    if z == 1:\n",
    "        return x2, y2\n",
    "    if z == 2:\n",
    "        return x3, y3\n",
    "\n",
    "def reader_pmtall(path):\n",
    "    extra = np.arange(4096, 4480)\n",
    "    tree = uproot.open(path)[\"tree\"]\n",
    "    pmtall = tree.array(\"PMTALL\")\n",
    "    pmtall = np.delete(pmtall, extra, axis=1)\n",
    "    return pmtall\n",
    "\n",
    "def reader(path,branch,number):\n",
    "    tree = uproot.open(path)[\"tree\"]\n",
    "    column = tree.array(branch)\n",
    "    column = column[:,number]\n",
    "    return column\n",
    "\n",
    "def reader_lone(path,branch):\n",
    "    tree = uproot.open(path)[\"tree\"]\n",
    "    column = tree.array(branch)\n",
    "    return column\n",
    "\n",
    "def pmtall_pedestal(path):\n",
    "    pedestal = reader(path,\"Pedestal\",0)\n",
    "    pmtall = reader_pmtall(path)\n",
    "    for i in range(len(pedestal)):\n",
    "        pmtall[i] = -(pmtall[i]-pedestal[i])\n",
    "    \n",
    "    return pmtall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb(one,two,three,four,five,six,seven,eight,nine,ten,portion):\n",
    "    one1,one2 = sep(one,1,portion)\n",
    "    two1,two2 = sep(two,1,portion)\n",
    "    three1,three2 = sep(three,1,portion)\n",
    "    four1,four2 = sep(four,1,portion)\n",
    "    five1,five2 = sep(five,1,portion)\n",
    "    six1,six2 = sep(six,0,portion)\n",
    "    seven1,seven2 = sep(seven,0,portion)\n",
    "    eight1,eight2 = sep(eight,0,portion)\n",
    "    nine1,nine2 = sep(nine,0,portion)\n",
    "    ten1,ten2 = sep(ten,0,portion)\n",
    "\n",
    "    z = np.concatenate((one1,two1,three1,four1,five1,six1,seven1,eight1,nine1,ten1),axis=0)\n",
    "    y = np.concatenate((one2,two2,three2,four2,five2,six2,seven2,eight2,nine2,ten2),axis=0)\n",
    "    return z, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "build it using python class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "class Waveform():\n",
    "    \n",
    "    def __init__(self, path=None, no_classes=None):\n",
    "        if path is None:\n",
    "            raise ValueError(\"Insert file path!\")\n",
    "        if no_classes is None:\n",
    "            raise ValueError(\"Number of classes?\")\n",
    "        \n",
    "        # Load PMTALL(sum of waveform of CANDLES), removing last portion of data\n",
    "        tree = uproot.open(path)[\"tree\"]\n",
    "        extra = np.arange(4096,4480)\n",
    "        pmtall = tree.array(\"PMTALL\")\n",
    "        pmtall = np.delete(pmtall, extra, axis=1)\n",
    "        pedestal = tree.array(\"Pedestal\")\n",
    "        pedestal_sum = pedestal[:,0]\n",
    "        for i in range(len(pedestal_sum)):\n",
    "            pmtall[i] = -(pmtall[i]-pedestal_sum[i])\n",
    "#         number = \n",
    "        \n",
    "        # random labelling(test purposes)\n",
    "        self.waveform = pmtall\n",
    "        self.label = np.random.randint(3,size=(len(pmtall),))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.waveform.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return (self.waveform[idx],self.label[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_classes = 3\n",
    "dataset = Waveform(path=\"Run009-069-001.root\", no_classes=no_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "from torch.utils.data import DataLoader\n",
    "data_loader = DataLoader(dataset=dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         num_workers=3) \n",
    "\n",
    "# #Testing#\n",
    "# for i in dataset:\n",
    "#     print(len(i[0]),len(i[1]))\n",
    "# for i in data_loader:\n",
    "#     print(i[0].size())\n",
    "#     print(i[1].size())\n",
    "# print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41260\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "n_batches = int(len(dataset)/BATCH_SIZE) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define CNN structure\n",
    "using an autoencoder for self-training, taking encoder part or decoder part for features learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "print(torch.randn(10,10).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder\n",
      "Autoencoder(\n",
      "  (norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (cv1): Conv1d(1, 32, kernel_size=(8,), stride=(4,), padding=(1,))\n",
      "  (pl1): MaxPool1d(kernel_size=2, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cv21): Conv1d(32, 16, kernel_size=(8,), stride=(4,), padding=(1,))\n",
      "  (pl21): MaxPool1d(kernel_size=2, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cv22): Conv1d(32, 16, kernel_size=(8,), stride=(4,), padding=(1,))\n",
      "  (pl22): MaxPool1d(kernel_size=2, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (ct1): ConvTranspose1d(16, 32, kernel_size=(8,), stride=(8,))\n",
      "  (ct2): ConvTranspose1d(32, 64, kernel_size=(10,), stride=(8,), padding=(1,))\n",
      "  (ct3): ConvTranspose1d(64, 1, kernel_size=(6,), stride=(4,), padding=(1,))\n",
      ")\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "torch.Size([32, 1, 8])\n",
      "torch.Size([32])\n",
      "torch.Size([16, 32, 8])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 32, 8])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 32, 8])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 64, 10])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 1, 6])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# BATCH_SIZE=2000\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Discriminator\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_chn, no_classes, kernel_size, \n",
    "                 no_filters, padding, maxpool, batch_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.input_chn = input_chn\n",
    "        self.no_classes = no_classes\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.no_filters = no_filters\n",
    "        self.maxpool = maxpool\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "#         self.norm = nn.BatchNorm1d(input_chn)\n",
    "        self.c1 = nn.Conv1d(input_chn ,no_filters ,kernel_size ,padding=padding )\n",
    "        self.p1 = nn.MaxPool1d(maxpool ,padding )\n",
    "        self.lr = nn.LeakyReLU(0.2)\n",
    "        self.c2 = nn.Conv1d(no_filters, int(no_filters/2), kernel_size, padding=padding)\n",
    "        self.p2 = nn.MaxPool1d(maxpool ,padding )       \n",
    "        self.l1 = nn.Linear(4096,64)\n",
    "        self.h1 = nn.Linear(64,64)\n",
    "        self.out = nn.Linear(64, no_classes)  \n",
    "        self.sg = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "#         x = inputs.view(self.batch_size,1,-1)\n",
    "#         x = self.norm(x)\n",
    "        x = self.c1(x)\n",
    "        x = self.lr(x)\n",
    "        x = self.p1(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.lr(x)\n",
    "        x = self.p2(x)\n",
    "        \n",
    "        x = x.view(self.batch_size,-1)\n",
    "        \n",
    "        x = self.l1(x)\n",
    "        x = self.lr(x)\n",
    "        x = self.h1(x)\n",
    "        x = self.out(x)\n",
    "        outputs = self.sg(x)\n",
    "        return outputs\n",
    "    \n",
    "# Autoencoder\n",
    "# WIP!\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,batch_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.norm = nn.BatchNorm1d(1)\n",
    "        self.cv1 = nn.Conv1d(1,32,8,4,padding=1)\n",
    "        self.pl1 = nn.MaxPool1d(2,4)\n",
    "        self.cv21 = nn.Conv1d(32,16,8,4,padding=1)\n",
    "        self.pl21 = nn.MaxPool1d(2,4)\n",
    "        self.cv22 = nn.Conv1d(32,16,8,4,padding=1)\n",
    "        self.pl22 = nn.MaxPool1d(2,4)\n",
    "\n",
    "        self.ct1 = nn.ConvTranspose1d(16,32,8,8)\n",
    "        self.ct2 = nn.ConvTranspose1d(32,64,10,8,padding=1)\n",
    "        self.ct3 = nn.ConvTranspose1d(64,1,6,4,padding=1)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h0 = self.norm(x)\n",
    "        h1 = F.relu(self.pl1(self.cv1(h0)))\n",
    "        return self.pl21(self.cv21(h1)), self.pl22(self.cv22(h1))\n",
    "    \n",
    "    def reparameterise(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        h3 = F.relu(self.ct1(z))\n",
    "        h3 = F.relu(self.ct2(h3))\n",
    "        return F.sigmoid(self.ct3(h3))\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        mu, logvar = self.encoder(inputs)\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar\n",
    "        \n",
    "\n",
    "# CNN = Classifier(1, no_classes=3, kernel_size=8, no_filters=32, \n",
    "#                  padding=4, maxpool=2, batch_size=BATCH_SIZE) \n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(CNN.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# print(CNN)\n",
    "# for parameter in CNN.parameters():\n",
    "#     print(parameter.size())\n",
    "\n",
    "print(\"Autoencoder\")\n",
    "\n",
    "GEN = Autoencoder(BATCH_SIZE)\n",
    "print(GEN)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(GEN.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "for parameter in GEN.parameters():\n",
    "    print(parameter.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#DUMMY WORKSPACE\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7faf2b38c0f0>\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "print(\"#DUMMY WORKSPACE\")    \n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "print(data_loader)\n",
    "\n",
    "# TEST = CNN(Variable(torch.randn(BATCH_SIZE,1,4096)))\n",
    "TEST = GEN.encoder(Variable(torch.randn(BATCH_SIZE,1,4096)))\n",
    "DATA = TEST[0].reshape(BATCH_SIZE,1,-1)\n",
    "print(TEST[0].size())\n",
    "print(TEST[1].size())\n",
    "\n",
    "print(DATA.size())\n",
    "# print(TEST[2].size())\n",
    "# print(TEST[0].detach().numpy())\n",
    "\n",
    "\n",
    "# print(\"DBSCAN\")\n",
    "# db = DBSCAN(eps=0.3, min_samples=20).fit(DATA.detach().numpy())\n",
    "# print(db.core_sample_indices_)\n",
    "# print(db.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training\n",
    "transform to Torch.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def to_var(x):\n",
    "    # first move to GPU, if necessary\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        \n",
    "    return Variable(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy code workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Overflow when unpacking long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-a1ac51c27761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(output,target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', dtype='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_number_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSCALE_FORMAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_number_format\u001b[0;34m(tensor, min_sz)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# TODO: use fmod?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mint_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Overflow when unpacking long"
     ]
    }
   ],
   "source": [
    "output = Variable(torch.randn(10,120))\n",
    "target = Variable(torch.FloatTensor(10).uniform_(0, 120).long())\n",
    "print(torch.FloatTensor(10))\n",
    "print(torch.FloatTensor(10).uniform_(0,1).long())\n",
    "# print(output,target)\n",
    "\n",
    "loss = criterion(output,target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 16, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danny/.local/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/2], Step[2/40], loss=12.8684, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[4/40], loss=12.1236, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[6/40], loss=11.9357, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[8/40], loss=12.3148, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[10/40], loss=11.7095, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[12/40], loss=15.2681, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[14/40], loss=12.3177, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[16/40], loss=12.6584, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[18/40], loss=12.2227, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[20/40], loss=12.1669, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[22/40], loss=13.1484, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[24/40], loss=12.2051, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[26/40], loss=11.9898, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[28/40], loss=11.9042, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[30/40], loss=14.0810, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[32/40], loss=13.0357, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[34/40], loss=12.1832, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[36/40], loss=13.0407, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[38/40], loss=11.7384, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[40/40], loss=12.4166, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[0/2], Step[42/40], loss=12.0467, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([260, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[2/40], loss=12.0497, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[4/40], loss=12.0828, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[6/40], loss=12.9957, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[8/40], loss=12.1404, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[10/40], loss=13.2171, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[12/40], loss=14.6194, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[14/40], loss=12.2836, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[16/40], loss=12.4395, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[18/40], loss=12.6784, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[20/40], loss=12.6470, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[22/40], loss=12.5110, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[24/40], loss=15.0734, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[26/40], loss=11.8417, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[28/40], loss=12.9659, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[30/40], loss=12.0407, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[32/40], loss=12.3311, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[34/40], loss=12.4553, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[36/40], loss=12.2639, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[38/40], loss=12.6759, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[40/40], loss=12.0680, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n",
      "Epoch[1/2], Step[42/40], loss=13.1361, Mean Discriminator output=BLANK.4f\n",
      "torch.Size([260, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 2\n",
    "\n",
    "\n",
    "\n",
    "# allow for manual keyboard interrupt\n",
    "try: \n",
    "    # loop through epochs\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        for batch_number, (waveform,label) in enumerate(data_loader):\n",
    "            \n",
    "#             print(\"epoch=\",epoch)\n",
    "#             print(batch_number)\n",
    "#             print(waveform.size(),label.size())\n",
    "    \n",
    "            batch_size = waveform.size()[0]\n",
    "            training_data = to_var(waveform.view(batch_size,1,4096))\n",
    "            target = training_data\n",
    "            \n",
    "#             print(training_data,target)\n",
    "            \n",
    "            outputs = GEN(training_data)\n",
    "#             print(outputs, target.view(-1).long())\n",
    "            \n",
    "#             print(outputs[0].size())\n",
    "#             print(training_data.size())\n",
    "            loss = criterion(outputs[0], target)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "#             print(loss.data[0])\n",
    "        \n",
    "            if (batch_number +1)%2 == 0:\n",
    "                print(\"Epoch[%d/%d], Step[%d/%d], loss=%.4f, Mean Discriminator output=BLANK.4f\"\n",
    "                      %(epoch,\n",
    "                        N_EPOCHS,\n",
    "                        batch_number+1,\n",
    "                        n_batches,\n",
    "                        loss.data[0] ))\n",
    "            \n",
    "#             print(GEN.state_dict())\n",
    "            torch.save(GEN.state_dict(), \"GEN_%d%d.pkl\"%(epoch,N_EPOCHS))\n",
    "            print(GEN.encoder(training_data)[0].size())\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Training ended early.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing output of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "Features = torch.randn(41260,16,16)\n",
    "print(Features[:1000].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "1 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "2 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "3 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "4 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "5 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "6 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "7 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "8 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "9 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "10 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "11 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "12 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "13 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "14 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "15 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "16 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "17 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "18 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "19 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "20 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "21 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "22 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "23 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "24 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "25 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "26 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "27 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "28 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "29 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "30 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "31 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "32 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "33 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "34 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "35 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "36 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "37 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "38 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "39 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "40 torch.Size([1000])\n",
      "torch.Size([1000, 4096])\n",
      "1000\n",
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n",
      "41 torch.Size([260])\n",
      "torch.Size([260, 4096])\n",
      "260\n",
      "torch.Size([260, 16, 16])\n",
      "torch.Size([41260, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for batch_number, (waveform,label) in enumerate(data_loader):\n",
    "\n",
    "        print(batch_number,label.size())\n",
    "        print(waveform.size())\n",
    "\n",
    "        batch_size = waveform.size()[0]\n",
    "        print(batch_size)\n",
    "        feat = GEN.encoder(to_var(waveform.view(batch_size,1,4096)))\n",
    "        print(feat[0].size())\n",
    "        Features[batch_number*1000:(batch_number+1)*1000] = feat[0]\n",
    "\n",
    "        print(Features.size())\n",
    "    # db = DBSCAN(eps=0.3, min_samples=20).fit(DATA.detach().numpy())\n",
    "    # print(db.core_sample_indices_)\n",
    "    # print(db.labels_)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Training ended early.')\n",
    "## PLOT the test results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41260, 256])\n"
     ]
    }
   ],
   "source": [
    "generated = Features.view(-1,256)\n",
    "print(generated.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danny/.local/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n",
      "/home/danny/.local/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 9997 9998 9999]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db = DBSCAN(eps=0.5, min_samples=20).fit(generated[:10000].detach().numpy())\n",
    "print(db.core_sample_indices_)\n",
    "print(db.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5450141240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(db.labels_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting filters/features\n",
    "\n",
    "Use the protion of the Autoencoder transfer the trained weight to semi-half model of autoencoder.\n",
    "Uses the output of the midlle layer of autoencoder and do a clustering on it.\n",
    "\n",
    "The cluster number is a single vector(multi-class in keras?) representing the \"output\" of the group class.\n",
    "\n",
    "# How to let this last layer of output automatically deduce itself.?\n",
    "* save every sample output? how to make gives a supervised like methods output??\n",
    "\n",
    "#Retrain the network but freeze all layer except for the last layer (clustering analysis layer). this can uses for LWRP studies, identify physical meaning of grouping. with it?\n",
    "\n",
    "* understanding Neural Network, how to get layer-wise relevance propagation work for the last layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering techniques\n",
    "most likely DBSCAN don't require to specify number of clusters however this can explode making difficult to use, the best option for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Wise Relevance Propagation Or similiar techniques\n",
    "The purpose of understanding CNN, see which portion of data gives more importance, mostly likely create a new CNN using trained weights from autoencoder with the final layers self-created based of the results of clustering. This can allow us to treate this CNN as supervised technique like however in reality as it is based on purely unsupervised techniques. This supervised like technique allows us to use technique like layer wise relevance propagation to understand the CNN giving us insight of the working of features learned by the cNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
