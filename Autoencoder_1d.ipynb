{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 73 µs, sys: 1 µs, total: 74 µs\n",
      "Wall time: 80.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 12.0, 8.0\n",
    "\n",
    "from pyts.transformation import GADF,GASF\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import uproot\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Concatenate, Dense, Activation, Reshape, Conv1D , Conv2D, MaxPooling1D, MaxPooling2D\n",
    "from keras.layers import Dropout, Flatten, BatchNormalization, Embedding, LSTM, UpSampling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-construct waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard(x,height,decay):\n",
    "    y = height*np.exp(-x*decay)\n",
    "    return y\n",
    "\n",
    "def shifter(x,starts):\n",
    "    L = int(starts*len(x))\n",
    "    y = np.zeros(len(x))\n",
    "    y[:L] = np.zeros(L) \n",
    "    y[L:] = x[:(len(x)-L)]\n",
    "    return y\n",
    "\n",
    "def comb_standard(x,second,height_1,decay_1,height_2,decay_2):\n",
    "    L = int(second*len(x))\n",
    "    y = np.zeros(len(x))\n",
    "    y[:L] = standard(x[:L],height_1,decay_1)\n",
    "    y[L:] = standard(x[:(len(x)-L)],height_2,decay_2)\n",
    "    return y\n",
    "\n",
    "def noiser(x,strength):\n",
    "    y = x + np.random.normal(0,strength,len(x))\n",
    "    return y\n",
    "\n",
    "def noiser_long(x,strength):\n",
    "    noise = np.random.normal(0,strength,len(x))\n",
    "    y = x + np.cumsum(noise)*strength\n",
    "    return y\n",
    "\n",
    "def noiser_comb(x,sepfact,strength):\n",
    "    L = int(sepfact*len(x))\n",
    "    x[:L] = noiser(x[:L],strength)\n",
    "    x[L:] = noiser_long(x[L:],strength)\n",
    "    return x\n",
    "\n",
    "def array_maker(entries):\n",
    "    x = np.arange(0,1,1/4096)\n",
    "    x = np.expand_dims(x,axis=0)\n",
    "    x = np.tile(x,[entries,1])\n",
    "    return x\n",
    "\n",
    "def double(x,second,height_1,decay_1,height_2,decay_2,starts,sepfact=0.15,strength=0.02):\n",
    "    y = comb_standard(x,second,height_1,decay_1,height_2,decay_2)\n",
    "    y = shifter(y,starts)\n",
    "    y = noiser_comb(y,sepfact,strength)\n",
    "    return y\n",
    "\n",
    "def single(x,height,decay,starts,sepfact=0.15,strength=0.02):\n",
    "    y = standard(x,height,decay)\n",
    "    y = shifter(y,starts)\n",
    "    y = noiser_comb(y,sepfact,strength)\n",
    "    return y\n",
    "\n",
    "def event_creators_single(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(1,0.01)\n",
    "        r = np.random.normal(5,2)\n",
    "        s = np.random.normal(0.03,0.005)\n",
    "        x[i] = single(x[i],w,r,s)\n",
    "    return x\n",
    "\n",
    "def event_creators_single_2(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(1,0.01)\n",
    "        r = np.random.normal(10,2)\n",
    "        s = np.random.normal(0.03,0.005)\n",
    "        x[i] = single(x[i],w,r,s)\n",
    "    return x\n",
    "\n",
    "def event_creators_single_3(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(1,0.1)\n",
    "        r = np.random.normal(4,1)\n",
    "        s = np.random.normal(0.03,0.005)\n",
    "        x[i] = single(x[i],w,r,s)\n",
    "    return x\n",
    "\n",
    "def event_creators_sharp(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(1,0.01)\n",
    "        r = np.random.normal(100,20)\n",
    "        s = np.random.normal(0.03,0.005)\n",
    "        x[i] = single(x[i],w,r,s)    \n",
    "    return x\n",
    "\n",
    "def event_creators_double_equal(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(0.2,0.01)\n",
    "        p = np.random.normal(1,0.01)\n",
    "        q = np.random.normal(5,2)\n",
    "        r = np.random.normal(1,0.01)\n",
    "        s = np.random.normal(5,2)\n",
    "        t = np.random.normal(0.03,0.005)\n",
    "        x[i] = double(x[i],w,p,q,r,s,t)\n",
    "    return x\n",
    "    \n",
    "def event_creators_double_unequal(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(0.2,0.01)\n",
    "        p = np.random.normal(1,0.2)\n",
    "        q = np.random.normal(50,10)\n",
    "        r = np.random.normal(1,0.2)\n",
    "        s = np.random.normal(50,10)\n",
    "        t = np.random.normal(0.03,0.005)\n",
    "        x[i] = double(x[i],w,p,q,r,s,t)\n",
    "    return x\n",
    "\n",
    "def event_creators_sharp_fat(entries):\n",
    "    x = array_maker(entries)\n",
    "    for i in range(entries):\n",
    "        w = np.random.normal(0.015,0.001)\n",
    "        p = np.random.normal(1,0.2)\n",
    "        q = np.random.normal(100,20)\n",
    "        r = np.random.normal(0.2,0.05)\n",
    "        s = np.random.normal(5,2)\n",
    "        t = np.random.normal(0.03,0.005)\n",
    "        x[i] = double(x[i],w,p,q,r,s,t)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 7\n",
    "group = 5\n",
    "training_ratio = 0.7\n",
    "validation_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "\n",
    "def label(q,k):\n",
    "    x = np.zeros(len(q))\n",
    "    for i in range(len(q)):\n",
    "        x[i] = k\n",
    "    return x\n",
    "\n",
    "def sep(q,k,z):\n",
    "    y = label(q,k)\n",
    "    x1, x2 ,x3 = np.split(q,[int(len(q)*training_ratio),int(len(q)*(training_ratio+validation_ratio))])\n",
    "    y1, y2 ,y3 = np.split(y,[int(len(q)*training_ratio),int(len(q)*(training_ratio+validation_ratio))])\n",
    "    if z == 0:\n",
    "        return x1, y1\n",
    "    if z == 1:\n",
    "        return x2, y2\n",
    "    if z == 2:\n",
    "        return x3, y3\n",
    "    \n",
    "def comb(one,two,three,four,five,portion):\n",
    "    one1,one2 = sep(one,0,portion)\n",
    "    two1,two2 = sep(two,1,portion)\n",
    "    three1,three2 = sep(three,2,portion)\n",
    "    four1,four2 = sep(four,3,portion)\n",
    "    five1,five2 = sep(five,4,portion)\n",
    "#     six1,six2 = sep(six,5,portion)\n",
    "#     seven1,seven2 = sep(seven,6,portion)\n",
    "    \n",
    "    z = np.concatenate((one1,two1,three1,four1,five1),axis=0)\n",
    "    y = np.concatenate((one2,two2,three2,four2,five2),axis=0)\n",
    "    return z, y\n",
    "\n",
    "# def generator(x):\n",
    "#     while 1:\n",
    "#         beta = event_creators_single(1000)\n",
    "#         ls = event_creators_sharp(1000)\n",
    "#         dp_e = event_creators_double_equal(1000)\n",
    "#         dp_ue = event_creators_double_unequal(1000)\n",
    "#         lsbeta = event_creators_sharp_fat(1000)\n",
    "        \n",
    "#         alpha = event_creators_single_2(1000)\n",
    "#         gamma = event_creators_single_3(1000)\n",
    "        \n",
    "#         z1, z2 = comb(beta,ls,dp_e,dp_ue,lsbeta,alpha,gamma,x)\n",
    "#         s = np.random.permutation(np.arange(len(z2)))\n",
    "#         z1 = z1[s]\n",
    "#         z2 = z2[s]\n",
    "# #         print(len(z1))\n",
    "#         gasf = GASF(image_size=128, overlapping=False, scale='-1')\n",
    "        \n",
    "#         for i in range(len(z2)):\n",
    "#             d1 = np.expand_dims(z1[i],axis=0)\n",
    "# #             p = gasf.transform(d1)\n",
    "#             q = keras.utils.to_categorical(z2[i],classes)\n",
    "#             r = normalize(d1,norm=\"l1\")\n",
    "#             yield r,q\n",
    "\n",
    "# test = generator(2)\n",
    "# # print(next(test)[0][0])\n",
    "# print(next(test)[0][0].shape)\n",
    "# # print(next(test)[0][1].shape)\n",
    "# print(next(test)[1].shape)\n",
    "\n",
    "# from pyts.visualization import plot_gasf\n",
    "# plot_gasf(next(test)[0], image_size=128, overlapping=False, scale='-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n"
     ]
    }
   ],
   "source": [
    "def reader_pmtall(path):\n",
    "    extra = np.arange(4096, 4480)\n",
    "    \n",
    "    tree = uproot.open(path)[\"tree\"]\n",
    "    pmtall = tree.array(\"PMTALL\")\n",
    "    pmtall = np.delete(pmtall, extra, axis=1)\n",
    "    return pmtall\n",
    "\n",
    "def reader(path,branch,number):\n",
    "    tree = uproot.open(path)[\"tree\"]\n",
    "    column = tree.array(branch)\n",
    "    column = column[:,number]\n",
    "    return column\n",
    "\n",
    "def reader_lone(path,branch):\n",
    "    tree = uproot.open(path)[\"tree\"]\n",
    "    column = tree.array(branch)\n",
    "    return column\n",
    "\n",
    "def pmtall_pedestal(path):\n",
    "    pedestal = reader(path,\"Pedestal\",0)\n",
    "    pmtall = reader_pmtall(path)\n",
    "    for i in range(len(pedestal)):\n",
    "        pmtall[i] = -(pmtall[i]-pedestal[i])\n",
    "    \n",
    "    return pmtall\n",
    "\n",
    "def generator(x):\n",
    "    while 1:\n",
    "        alpha = pmtall_pedestal(\"Alpha.root\")\n",
    "#         bad1 = pmtall_pedestal(\"BAD_DATA_QUALITY_1.root\")\n",
    "#         bad2 = pmtall_pedestal(\"BAD_DATA_QUALITY_2.root\")\n",
    "        piled = pmtall_pedestal(\"Piled_2.root\")\n",
    "        ls = pmtall_pedestal(\"LS.root\")\n",
    "        lsbeta = pmtall_pedestal(\"lsbeta.root\")\n",
    "        ref = pmtall_pedestal(\"RefPulse009.root\")\n",
    "        \n",
    "        z1, z2 = comb(piled,ref,alpha,ls,lsbeta,x)\n",
    "        s = np.random.permutation(np.arange(len(z2)))\n",
    "        z1 = z1[s]\n",
    "        z2 = z2[s]\n",
    "\n",
    "#         para_piled = parameters(\"Piled_2.root\")\n",
    "#         para_ref = parameters(\"RefPulse009.root\")\n",
    "#         para_alpha = parameters(\"Alpha.root\")\n",
    "#         para_ls = parameters(\"LS.root\")\n",
    "#         para_lsbeta = parameters(\"lsbeta.root\")\n",
    "        \n",
    "#         z3, z4 = comb5(para_piled,para_ref,para_alpha,para_ls,para_lsbeta,x)        \n",
    "#         z3 = z3[s] \n",
    "#         z4 = z4[s]\n",
    "\n",
    "        gasf = GASF(image_size=128, overlapping=False, scale='-1')\n",
    "        \n",
    "        for i in range(len(z2)):\n",
    "            d1 = np.expand_dims(z1[i],axis=0)\n",
    "            q = keras.utils.to_categorical(z2[i],classes)\n",
    "            r = normalize(d1,norm=\"l1\")\n",
    "#             s = np.expand_dims(q,axis=0)\n",
    "            yield r,r\n",
    "\n",
    "test = generator(0)\n",
    "# print(next(test)[0][0])\n",
    "print(next(test)[0].shape)\n",
    "# print(next(test)[0][1].shape)\n",
    "# print(next(test)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_19 (Reshape)         (None, 4096, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 128, 16)           1040      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 4, 8)              8200      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 2, 8)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 1, 8)              4104      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_23 (UpSampling (None, 2, 8)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1, 16)             8208      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_24 (UpSampling (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 2, 1)              1025      \n",
      "=================================================================\n",
      "Total params: 22,577\n",
      "Trainable params: 22,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def multiple_inputs():\n",
    "    feeder_1d = Input(shape=(4096,))\n",
    "    model1 = Reshape((4096,1),input_shape=(4096,))(feeder_1d)\n",
    "    model1 = Conv1D(16, kernel_size=64, strides=32,padding='same',activation=\"relu\")(model1)\n",
    "    model1 = MaxPooling1D(pool_size=2,padding='same')(model1)\n",
    "    model1 = Conv1D(8, kernel_size=64, strides=16,padding='same',activation=\"relu\")(model1)\n",
    "    model1 = MaxPooling1D(pool_size=2,padding='same')(model1)\n",
    "    model1 = Conv1D(8, kernel_size=64, strides=16,padding='same',activation=\"relu\")(model1)\n",
    "    model1 = UpSampling1D(2)(model1)\n",
    "    model1 = Conv1D(16, kernel_size=64, strides=32,padding='same',activation=\"relu\")(model1)\n",
    "    model1 = UpSampling1D(2)(model1)\n",
    "#     model1 = Flatten()(model1)\n",
    "#     model1 = Dense(64,activation=\"relu\")(model1)\n",
    "#     model1 = Dropout(0.2)(model1)\n",
    "#     model1 = Dense(64,activation=\"relu\")(model1)\n",
    "#     model1 = Dropout(0.2)(model1)\n",
    "    waveform_1d_out = Conv1D(1, kernel_size=64, strides=1,padding='same',activation=\"sigmoid\")(model1)\n",
    "    \n",
    "#     feeder_2d = Input(shape=(128,128))\n",
    "#     model2 = Reshape((128,128,1),input_shape=(128,128))(feeder_2d)\n",
    "#     model2 = Conv2D(64, kernel_size=(8,8),strides=4,padding='same')(model2)\n",
    "#     model2 = MaxPooling2D(pool_size=2)(model2)\n",
    "#     model2 = Activation(\"relu\")(model2)\n",
    "#     model2 = Conv2D(32, kernel_size=(4,4),strides=4,padding='same')(model2)\n",
    "#     model2 = MaxPooling2D(pool_size=2)(model2)\n",
    "#     model2 = Activation(\"relu\")(model2)\n",
    "#     model2 = Dropout(0.2)(model2)\n",
    "#     model2 = Flatten()(model2)\n",
    "# #     model2 = Dense(256,activation=\"relu\")(model2)\n",
    "# #     model2 = Dropout(0.3)(model2)\n",
    "#     model2 = Dense(64,activation=\"relu\")(model2)\n",
    "#     model2 = Dropout(0.3)(model2)\n",
    "#     model2 = Dense(64,activation=\"relu\")(model2)\n",
    "#     model2 = Dropout(0.3)(model2)\n",
    "#     waveform_2d_out = Dense(7,activation=\"sigmoid\")(model2)\n",
    "    \n",
    "#     feeder_para = Input(shape=(10,))\n",
    "#     model3 = Dense(64,activation=\"relu\")(feeder_para)\n",
    "#     model3 = Dropout(0.2)(model3)\n",
    "#     model3 = Dense(64,activation=\"relu\")(model3)\n",
    "#     model3 = Dropout(0.2)(model3)\n",
    "# #     model3 = Dense(128,activation=\"relu\")(model3)\n",
    "# #     model3 = Dropout(0.2)(model3)\n",
    "#     para_dense = Dense(7,activation=\"sigmoid\")(model3)\n",
    "    \n",
    "#     x = keras.layers.concatenate([waveform_1d_out, waveform_2d_out])\n",
    "#     x = Dense(256,activation=\"relu\")(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = Dense(256,activation=\"relu\")(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     main_output = Dense(7, activation='softmax', name='main_output')(x)\n",
    "    \n",
    "    model = Model(inputs=[feeder_1d],outputs=[waveform_1d_out])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "mult = multiple_inputs()\n",
    "mult.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected conv1d_70 to have 3 dimensions, but got array with shape (1, 4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3e632b39def8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msteps_vt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3062\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_vt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1875\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected conv1d_70 to have 3 dimensions, but got array with shape (1, 4096)"
     ]
    }
   ],
   "source": [
    "train_gen = generator(0)\n",
    "val_gen = generator(1)\n",
    "test_gen = generator(2)\n",
    "\n",
    "steps_t = 21430\n",
    "steps_vt = 3062\n",
    "\n",
    "history = mult.fit_generator(train_gen,steps_per_epoch=steps_t, epochs=10, verbose=1, validation_data=val_gen,validation_steps=steps_vt)\n",
    "print(history.history.keys())\n",
    "plt.figure()\n",
    "plt.title(\"Classification accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(history.history['acc'],label=\"training accuracy\")\n",
    "plt.plot(history.history['val_acc'],label=\"Validation accuracy\")\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Loss function\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(history.history['loss'],label=\"training loss\")\n",
    "plt.plot(history.history['val_loss'],label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification accuracy =\",history.history['val_acc'][-1])\n",
    "\n",
    "# mult.save(\"GPU_CNN.h5\")\n",
    "\n",
    "score = mult.evaluate_generator(test_gen,steps=1531)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult.save(\"tuned_data_1d.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
