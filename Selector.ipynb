{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 299 ms, total: 1.42 s\n",
      "Wall time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 5.0, 4.0\n",
    "\n",
    "from pyts.transformation import GADF,GASF\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import uproot\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 4)\n"
     ]
    }
   ],
   "source": [
    "# Specifically for Run009 good data custom set\n",
    "n = 3000\n",
    "groups = np.array([[1,2,3,4],\n",
    "                 [1,2,3,4],\n",
    "                 [3,4,1,2],\n",
    "                 [1,2,3,4],\n",
    "                 [1,2,3,4],\n",
    "                 [3,4,1,2],\n",
    "                 [3,4,1,2],\n",
    "                 [1,2,3,4],\n",
    "                 [3,4,1,2],\n",
    "                 [3,4,1,2],\n",
    "                 [3,4,1,2],\n",
    "                 [3,4,1,2],\n",
    "                 [3,4,1,2],\n",
    "                 [1,2,3,4],\n",
    "                 [1,2,3,4],\n",
    "                 [3,4,1,2],\n",
    "                 [1,2,3,4],\n",
    "                 [3,4,1,2],\n",
    "                 [3,4,1,2],\n",
    "                 [1,2,3,4],\n",
    "                 [1,2,3,4],\n",
    "                 [3,4,1,2]])\n",
    "\n",
    "print(groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48 µs, sys: 1 µs, total: 49 µs\n",
      "Wall time: 53.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class Waveform():\n",
    "    \n",
    "    def __init__(self, path=None):\n",
    "        if path is None:\n",
    "            raise ValueError(\"Insert file path!\")\n",
    "        \n",
    "        # Load PMTALL(sum of waveform of CANDLES), removing last portion of data\n",
    "        tree = uproot.open(path)[\"tree\"]\n",
    "        \n",
    "        extra = np.arange(4096,4480)\n",
    "        pmtall = tree.array(\"PMTALL\")\n",
    "        pmtall = np.delete(pmtall, extra, axis=1)\n",
    "        pedestal = tree.array(\"Pedestal\")\n",
    "        pedestal_sum = pedestal[:,0]\n",
    "        for i in range(len(pedestal_sum)):\n",
    "            pmtall[i] = pedestal_sum[i] - pmtall[i]\n",
    "\n",
    "        self.waveform = normalize(pmtall,axis=1,norm=\"l2\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.waveform.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.waveform[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_classes = 3\n",
    "dataset = Waveform(path=\"Run9goodDataQ_dualgate.root\")\n",
    "\n",
    "BATCH_SIZE = 3000\n",
    "data_loader = DataLoader(dataset=dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for batch_number, waveform in enumerate(data_loader):\n",
    "        if batch_number="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65675\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "n_batches = int(len(dataset)/BATCH_SIZE) \n",
    "print(n_batches)\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder\n",
      "Autoencoder(\n",
      "  (cv1): Conv1d(1, 32, kernel_size=(8,), stride=(4,), padding=(4,))\n",
      "  (pl1): MaxPool1d(kernel_size=2, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cv21): Conv1d(32, 16, kernel_size=(8,), stride=(4,), padding=(4,))\n",
      "  (pl21): MaxPool1d(kernel_size=2, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cv22): Conv1d(32, 16, kernel_size=(8,), stride=(4,), padding=(4,))\n",
      "  (pl22): MaxPool1d(kernel_size=2, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (ct1): ConvTranspose1d(16, 32, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      "  (up1): Upsample(scale_factor=2, mode=nearest)\n",
      "  (ct2): ConvTranspose1d(32, 32, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      "  (up2): Upsample(scale_factor=2, mode=nearest)\n",
      "  (ct3): ConvTranspose1d(32, 1, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      ")\n",
      "torch.Size([32, 1, 8])\n",
      "torch.Size([32])\n",
      "torch.Size([16, 32, 8])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 32, 8])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 32, 8])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 32, 8])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 1, 8])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,batch_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "#         self.norm = nn.BatchNorm1d(1)\n",
    "        self.cv1 = nn.Conv1d(1, 32, kernel_size=8, stride=4, padding=4)\n",
    "        self.pl1 = nn.MaxPool1d(2, stride=4)\n",
    "        self.cv21 = nn.Conv1d(32, 16, kernel_size=8, stride=4, padding=4)\n",
    "        self.pl21 = nn.MaxPool1d(2, stride=4)\n",
    "        self.cv22 = nn.Conv1d(32, 16, kernel_size=8, stride=4, padding=4)\n",
    "        self.pl22 = nn.MaxPool1d(2, stride=4)\n",
    "                \n",
    "        self.ct1 = nn.ConvTranspose1d(16, 32, kernel_size=8, stride=4, padding=2)\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.ct2 = nn.ConvTranspose1d(32, 32, kernel_size=8, stride=4, padding=2)\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.ct3 = nn.ConvTranspose1d(32, 1, kernel_size=8, stride=4,padding=2)\n",
    "\n",
    "    def encoder(self, x):\n",
    "#         h0 = self.norm(x)\n",
    "        h1 = F.tanh(self.pl1(self.cv1(x)))\n",
    "        return self.pl21(self.cv21(h1)), self.pl22(self.cv22(h1))\n",
    "    \n",
    "    def reparameterise(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        h3 = F.leaky_relu(self.ct1(z))\n",
    "        h3 = self.up1(h3)\n",
    "        h3 = F.leaky_relu(self.ct2(h3))\n",
    "        h3 = self.up2(h3)\n",
    "        return F.leaky_relu(self.ct3(h3))\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        mu, logvar = self.encoder(inputs)\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar\n",
    "print(\"Autoencoder\")\n",
    "\n",
    "GEN = Autoencoder(BATCH_SIZE)\n",
    "print(GEN)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(GEN.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "for parameter in GEN.parameters():\n",
    "    print(parameter.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN.load_state_dict(torch.load(\"GEN_WEIGHT_quarter.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "        \n",
    "    return Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 16.2 s, total: 1min 20s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "label = []\n",
    "# label2 = []\n",
    "\n",
    "try:\n",
    "    for batch_number, waveform in enumerate(data_loader):\n",
    "        batch_size = waveform.size()[0]\n",
    "#         print(batch_size)\n",
    "        waveform_in = to_var(waveform.view(batch_size,1,4096)) \n",
    "#         feat = GEN(waveform_in)\n",
    "        features = GEN.encoder(waveform_in)\n",
    "        \n",
    "#         print(batch_number)\n",
    "#         print(feat[0].size())\n",
    "        \n",
    "        encoder_feat = np.reshape(features[0].detach().numpy(),(batch_size,-1))\n",
    "        Z = linkage(encoder_feat, method=\"ward\")\n",
    "        \n",
    "        clusters = fcluster(Z, 1.5, criterion='distance')\n",
    "#         print(clusters.shape)\n",
    "#         Y = linkage(encoder_feat[clusters==1], method=\"ward\")\n",
    "#         clusters2 = fcluster(Y, 1.5, criterion='distance')\n",
    "#         print(Y.shape)\n",
    "        \n",
    "#         print(clusters.size)\n",
    "#         print(np.unique(clusters))\n",
    "#         print(clusters2.size)\n",
    "#         print(np.unique(clusters2))\n",
    "        label.append(encoder_feat)\n",
    "#         label2 = np.append(label2,clusters2)\n",
    "        \n",
    "        \n",
    "#         for i, waveform_out in enumerate(feat[0]):\n",
    "#             if clusters[i] == 1:\n",
    "#                 plt.figure()\n",
    "#                 plt.plot(waveform[i])\n",
    "#                 plt.show()\n",
    "#             red = waveform_out.detach().numpy()\n",
    "#             blue = waveform_in[i].detach().numpy()\n",
    "\n",
    "        \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Training ended early.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save output, shuffle=False, use thisoutput to mod dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 256)\n",
      "(2675, 256)\n",
      "(65675, 256)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(label[0].shape)\n",
    "print(label[21].shape)\n",
    "cnn_feat = label[21]\n",
    "for i in range(21):\n",
    "    cnn_feat = np.concatenate((cnn_feat,label[0]),axis=0)\n",
    "print(cnn_feat.shape)\n",
    "np.save(\"encoder_feat\", cnn_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
